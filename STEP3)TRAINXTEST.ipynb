{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### PT\n",
        "Divide a base sintÃ©tica em conjuntos de treino (70%) e teste (30%) de forma aleatÃ³ria e salva cada um como CSV separado.\n",
        "\n",
        "ðŸ”¹ Treinamento (70%)\n",
        "Serve para o modelo aprender padrÃµes nos dados (comportamentos normais e fraudulentos).\n",
        "\n",
        "Ã‰ a base que alimenta os algoritmos de machine learning para ajustar os pesos e regras.\n",
        "\n",
        "ðŸ”¹ Teste (30%)\n",
        "Usado para avaliar o desempenho real do modelo em dados nunca vistos.\n",
        "\n",
        "Ajuda a verificar se o modelo generaliza bem e nÃ£o estÃ¡ simplesmente decorando os dados (overfitting).\n",
        "\n",
        "ðŸ”Ž VALIDAÃ‡ÃƒO.\n",
        "Para melhorar a performance, apÃ³s o primeiro treinamento e teste, serÃ¡ feita a validaÃ§Ã£o.\n",
        "\n",
        "Treino: 60%\n",
        "\n",
        "ValidaÃ§Ã£o: 20%\n",
        "\n",
        "Teste: 20%\n",
        "\n",
        "A validaÃ§Ã£o Ã© usada para:\n",
        "\n",
        "Ajustar hiperparÃ¢metros (ex: profundidade de Ã¡rvore, regularizaÃ§Ã£o etc.)\n",
        "\n",
        "Evitar overfitting durante o treinamento\n",
        "\n",
        "ðŸ“š Base de referÃªncia:\n",
        "\n",
        "Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow â€“ AurÃ©lien GÃ©ron\n",
        "\n",
        "Curso de Machine Learning da EBAC, Coursera e Kaggle\n",
        "\n",
        "PrÃ¡ticas padrÃ£o em bibliotecas como sklearn.model_selection.train_test_split\n",
        "\n",
        "### EN\n",
        "Splits the synthetic dataset into training (70%) and testing (30%) sets randomly and saves each as a separate CSV file.\n",
        "\n",
        "ðŸ”¹ Training (70%)  \n",
        "Used for the model to learn patterns in the data (normal and fraudulent behaviors).  \n",
        "\n",
        "This dataset feeds the machine learning algorithms to adjust weights and rules.  \n",
        "\n",
        "ðŸ”¹ Testing (30%)  \n",
        "Used to evaluate the model's real performance on unseen data.  \n",
        "\n",
        "Helps check if the model generalizes well and is not just memorizing the data (overfitting).  \n",
        "\n",
        "ðŸ”Ž VALIDATION  \n",
        "To improve performance, after the first training and testing, validation is performed.  \n",
        "\n",
        "Training: 60%  \n",
        "Validation: 20%  \n",
        "Testing: 20%  \n",
        "\n",
        "Validation is used to:  \n",
        "- Tune hyperparameters (e.g., tree depth, regularization, etc.)  \n",
        "- Prevent overfitting during training  \n",
        "\n",
        "ðŸ“š Reference sources:  \n",
        "- *Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow* â€“ AurÃ©lien GÃ©ron  \n",
        "- Machine Learning courses from EBAC, Coursera, and Kaggle  \n",
        "- Standard practices in libraries like `sklearn.model_selection.train_test_split`\n"
      ],
      "metadata": {
        "id": "9HBAx4FOOOMO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dwxGh49XOIkN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b60e967-703f-485b-b593-05de02824a56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho do conjunto de treino: (7000, 12)\n",
            "Tamanho do conjunto de teste: (3000, 12)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv('banco_dados_sintetico_operadora.csv') #ApÃ³s o STEP 2\n",
        "\n",
        "# Dividir em treino e teste (70% treino, 30% teste)\n",
        "# X = df.drop('fraudulento', axis=1)\n",
        "# y = df['fraudulento']\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Dividir o DataFrame completo aleatoriamente:\n",
        "train_df, test_df = train_test_split(df, test_size=0.3, random_state=42)\n",
        "\n",
        "# Verificar tamanhos\n",
        "print(\"Tamanho do conjunto de treino:\", train_df.shape)\n",
        "print(\"Tamanho do conjunto de teste:\", test_df.shape)\n",
        "\n",
        "# Salvar arquivos separados:\n",
        "train_df.to_csv('treino_dados_sintetico.csv', index=False)\n",
        "test_df.to_csv('teste_dados_sintetico.csv', index=False)\n"
      ]
    }
  ]
}